# Load the uploaded spam.csv dataset
import pandas as pd

# Read the uploaded CSV file
df = pd.read_csv("spam.csv", encoding='latin-1')

# Display the first few rows to understand the structure
df.head()

# Keep only required columns and rename
df = df[["v1", "v2"]]
df.columns = ["label", "text"]

# Convert labels to binary (ham = 0, spam = 1)
df["label"] = df["label"].map({"ham": 0, "spam": 1})

#Train-Test Split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(df["text"], df["label"], test_size=0.2, random_state=42)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

vocab_size = 10000
max_len = 100

tokenizer = Tokenizer(num_words=vocab_size, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')

import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, 64, input_length=max_len),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

history = model.fit(
    X_train_pad, y_train,
    epochs=5,
    validation_data=(X_test_pad, y_test),
    batch_size=32
)

loss, accuracy = model.evaluate(X_test_pad, y_test)
print(f"Test Accuracy: {accuracy:.4f}")

sample_msg = ["You won a FREE ticket to Bahamas! Reply YES to claim."]
sample_seq = tokenizer.texts_to_sequences(sample_msg)
sample_pad = pad_sequences(sample_seq, maxlen=max_len, padding='post')
prediction = model.predict(sample_pad)
print("Spam" if prediction[0][0] > 0.5 else "Ham")
